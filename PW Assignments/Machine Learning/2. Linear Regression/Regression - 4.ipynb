{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b744c5",
   "metadata": {},
   "source": [
    "**QI. What is Lasso Regression, and how does it differ from other regression techniques?**\n",
    "- Lasso Regression is a regression technique that performs both feature selection and regularization. It differs from other regression techniques by adding a penalty term to the cost function that penalizes the magnitude of the coefficients.\n",
    "\n",
    "**Q2. What is the main advantage of using Lasso Regression in feature selection?**\n",
    "- The main advantage of using Lasso Regression in feature selection is that it can automatically select the most important features by shrinking the coefficients of irrelevant features to zero.\n",
    "\n",
    "**Q3. How do you interpret the coefficients of a Lasso Regression model?**\n",
    "- The coefficients of a Lasso Regression model can be interpreted similarly to the coefficients of other regression models, but they should be interpreted with caution as they are biased.\n",
    "\n",
    "**Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?**\n",
    "- The main tuning parameter in Lasso Regression is the regularization parameter (lambda). Lambda controls the amount of shrinkage applied to the coefficients. Higher values of lambda result in more shrinkage and more feature selection.\n",
    "\n",
    "**Q5. Can Lasso Regression be used for nonâ€”linear regression problems? If yes, how?**\n",
    "- Yes, Lasso Regression can be used for non-linear regression problems by using kernel methods. Kernel methods transform the input features into a higher-dimensional space where the relationship between the features and the target variable is more likely to be linear.\n",
    "\n",
    "**Q6. What is the difference between Ridge Regression and Lasso Regression?**\n",
    "- The difference between Ridge Regression and Lasso Regression is that Ridge Regression penalizes the squared magnitude of the coefficients, while Lasso Regression penalizes the absolute magnitude of the coefficients. This means that Lasso Regression is more likely to shrink the coefficients of irrelevant features to zero, resulting in more feature selection.\n",
    "\n",
    "**Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
    "- Yes, Lasso Regression can handle multicollinearity in the input features by shrinking the coefficients of correlated features towards zero. This reduces the impact of multicollinearity on the model's predictions.\n",
    "\n",
    "**Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
    "- There are a number of ways to choose the optimal value of lambda in Lasso Regression. One common approach is to use cross-validation. Cross-validation involves splitting the training data into multiple folds and training the model on each fold with a different value of lambda. The optimal value of lambda is then chosen as the value that produces the best performance on the held-out fold(s)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
