{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aa6c55",
   "metadata": {},
   "source": [
    "**QI. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?**\n",
    "\n",
    "Polynomial functions and kernel functions are both used to transform data into a higher-dimensional space, where it can be more easily separated by a linear classifier. Kernel functions are a more general way of doing this, and they can be used to transform data into any type of space, not just a polynomial space.\n",
    "\n",
    "**Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?**\n",
    "\n",
    "Here is an example of how to implement an SVM with a polynomial kernel in Python using Scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of the SVC classifier with a polynomial kernel\n",
    "clf = SVC(kernel='poly', degree=2)\n",
    "\n",
    "# Train the classifier on the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = clf.predict(X_new)\n",
    "```\n",
    "\n",
    "**Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?**\n",
    "\n",
    "Increasing the value of epsilon will increase the number of support vectors in SVR. This is because a larger epsilon will allow for more points to fall outside of the margin, which will make them support vectors.\n",
    "\n",
    "**Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?**\n",
    "\n",
    "* **Choice of kernel function:** The choice of kernel function will affect the shape of the decision boundary. A polynomial kernel will create a more curved decision boundary, while a linear kernel will create a straight decision boundary.\n",
    "\n",
    "* **C parameter:** The C parameter is a regularization parameter that controls the trade-off between fitting the training data and keeping the decision boundary simple. A larger C parameter will make the decision boundary more complex, which may improve performance on the training data but may also lead to overfitting. A smaller C parameter will make the decision boundary simpler, which may improve performance on new data but may also lead to underfitting.\n",
    "\n",
    "* **Epsilon parameter:** The epsilon parameter is a tolerance parameter that controls how much error the SVR is allowed to make. A larger epsilon parameter will allow the SVR to make more mistakes, which may improve performance on noisy data. A smaller epsilon parameter will make the SVR less tolerant of mistakes, which may improve performance on clean data.\n",
    "\n",
    "* **Gamma parameter:** The gamma parameter is a parameter that controls the shape of the kernel function. A larger gamma parameter will create a kernel function that is more sensitive to local changes in the data. A smaller gamma parameter will create a kernel function that is less sensitive to local changes in the data.\n",
    "\n",
    "**Q5. Assignment:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a474a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Separate the features and target\n",
    "X = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = iris['species']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Preprocess the data\n",
    "# ... (e.g. scaling, normalization)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b967b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
